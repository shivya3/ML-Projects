{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-MAJOR-DEC-AI12B3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9vErjbNf10"
      },
      "source": [
        "INSTALLING THE PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiaxAXU6c8P",
        "outputId": "9560c6c3-5087-47df-ef94-b6654def8230"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1lZj4mv6uFU"
      },
      "source": [
        "LOADING THE LIBRARIES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kdAUXkYNmG_"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOvqGWh4FLcp"
      },
      "source": [
        "UNZIPPING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE67BI4x_w5T",
        "outputId": "8a7c0f7e-9d70-469e-eacd-78b5708a8bb6"
      },
      "source": [
        "!unzip /content/dataset-20210221T080358Z-001.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/dataset-20210221T080358Z-001.zip\n",
            "replace dataset/without_mask/262.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_jMCW_tKRRQ"
      },
      "source": [
        "LOADING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZWKMhujKe-p",
        "outputId": "473d98d4-a36a-4970-9a50-d6add18c0e44"
      },
      "source": [
        "data_path= '/content/dataset'\n",
        "os.path.exists(data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqSRqxkLf36"
      },
      "source": [
        "EXTRACTING FEATURES AND TARGET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YguP1kwxARsT",
        "outputId": "a22f6afc-b327-4061-9b78-461d6ee77ca1"
      },
      "source": [
        "categories= os.listdir(data_path)\n",
        "labels =[i for i in range(len(categories))]\n",
        "label_dict =dict(zip(categories,labels)) \n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'without_mask': 0, 'with_mask': 1}\n",
            "['without_mask', 'with_mask']\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZB0HnUALkTz"
      },
      "source": [
        "img_size=100\n",
        "data=[]\n",
        "target=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyxjXUDXL43f"
      },
      "source": [
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "        \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
        "        resized=cv2.resize(gray,(img_size,img_size))\n",
        "        data.append(resized)\n",
        "        target.append(label_dict[category]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKQ97182MB03"
      },
      "source": [
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target=np.array(target)\n",
        "new_target=np_utils.to_categorical(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yEcu5WBMQPv"
      },
      "source": [
        "np.save('data',data)\n",
        "np.save('target',new_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGnes0uoMQW9"
      },
      "source": [
        "data=np.load('data.npy')\n",
        "target=np.load('target.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVFwlYjmOqOR"
      },
      "source": [
        "ARCHITECTURE OF THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yWaiICGMQqO"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z52ZRZkXM2Az"
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgs7whi-Mhvv"
      },
      "source": [
        "\n",
        "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r69NyVCQMh7U"
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(2,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFBzlThZOxwC"
      },
      "source": [
        "COMPILING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwzvS-ZyNi28"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iLbnNyYPa0p"
      },
      "source": [
        "TRAINING, TESTING AND FITTING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjEv3xYLNjJJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiqP9jGDNjWh",
        "outputId": "b706ecc5-3640-4150-afcc-250a3b091894"
      },
      "source": [
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
        "history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 3.0461 - accuracy: 0.5060 - val_loss: 0.6721 - val_accuracy: 0.4955\n",
            "INFO:tensorflow:Assets written to: model-001.model/assets\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 41s 1s/step - loss: 0.6460 - accuracy: 0.6103 - val_loss: 0.5590 - val_accuracy: 0.7364\n",
            "INFO:tensorflow:Assets written to: model-002.model/assets\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 30s 1s/step - loss: 0.4772 - accuracy: 0.7722 - val_loss: 0.4344 - val_accuracy: 0.7955\n",
            "INFO:tensorflow:Assets written to: model-003.model/assets\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.3174 - accuracy: 0.8710 - val_loss: 0.4101 - val_accuracy: 0.7955\n",
            "INFO:tensorflow:Assets written to: model-004.model/assets\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 30s 1s/step - loss: 0.2510 - accuracy: 0.8960 - val_loss: 0.2717 - val_accuracy: 0.9091\n",
            "INFO:tensorflow:Assets written to: model-005.model/assets\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.1282 - accuracy: 0.9634 - val_loss: 0.2856 - val_accuracy: 0.8909\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 30s 1s/step - loss: 0.1200 - accuracy: 0.9618 - val_loss: 0.2855 - val_accuracy: 0.8909\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 30s 1s/step - loss: 0.0723 - accuracy: 0.9859 - val_loss: 0.2439 - val_accuracy: 0.9000\n",
            "INFO:tensorflow:Assets written to: model-008.model/assets\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0416 - accuracy: 0.9946 - val_loss: 0.2699 - val_accuracy: 0.8773\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0375 - accuracy: 0.9940 - val_loss: 0.2496 - val_accuracy: 0.9000\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.2343 - val_accuracy: 0.9045\n",
            "INFO:tensorflow:Assets written to: model-011.model/assets\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.2334 - val_accuracy: 0.8909\n",
            "INFO:tensorflow:Assets written to: model-012.model/assets\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 32s 1s/step - loss: 0.0143 - accuracy: 0.9998 - val_loss: 0.2551 - val_accuracy: 0.9000\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 32s 1s/step - loss: 0.0151 - accuracy: 0.9985 - val_loss: 0.2988 - val_accuracy: 0.8955\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0132 - accuracy: 0.9997 - val_loss: 0.2302 - val_accuracy: 0.9045\n",
            "INFO:tensorflow:Assets written to: model-015.model/assets\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.2395 - val_accuracy: 0.9045\n",
            "Epoch 17/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.2499 - val_accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0130 - accuracy: 0.9998 - val_loss: 0.2275 - val_accuracy: 0.9136\n",
            "INFO:tensorflow:Assets written to: model-018.model/assets\n",
            "Epoch 19/20\n",
            "28/28 [==============================] - 30s 1s/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.2403 - val_accuracy: 0.9091\n",
            "Epoch 20/20\n",
            "28/28 [==============================] - 31s 1s/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 0.2357 - val_accuracy: 0.9182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ZQIVHZPnUc"
      },
      "source": [
        "EVALUATING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkf5ar-N86P",
        "outputId": "42d955eb-9c32-4e24-f5dc-67ae7ff828f3"
      },
      "source": [
        "print(model.evaluate(test_data,test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 2s 189ms/step - loss: 0.4030 - accuracy: 0.8986\n",
            "[0.40299472212791443, 0.8985507488250732]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgb3m1a-OO_5"
      },
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx7sq41aOYFI"
      },
      "source": [
        "model = load_model('model-015.model')\n",
        "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "source=cv2.VideoCapture(0)\n",
        "\n",
        "labels_dict={0:'  MASK',1:'NO MASK'}\n",
        "color_dict={0:(0,255,0),1:(0,0,255)}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}